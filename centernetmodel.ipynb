{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SIDHARTH06/ROI_Cutter/blob/master/centernetmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8QjTXrymO3x",
        "outputId": "c176f432-aa61-4fc9-c8c7-a288106e2bd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[K     |████████████████████████████████| 431 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqSNcOp1RRht"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-b6zUiQmUXY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.optim import Adam\n",
        "import timm\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4qWoRFsKqe1"
      },
      "outputs": [],
      "source": [
        "class downSample(nn.Module):\n",
        "  def __init(self):\n",
        "    super(downSample, self).__init__()\n",
        "    self.ag=nn.AvgPool2d(3,stride=1)\n",
        "  def forward(self,X):\n",
        "    X=self.ag(X)\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6kL2CBXnrky"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, pretrained = False, backbone = \"resnet34\"):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.backbone_net = timm.create_model(backbone, pretrained = pretrained)\n",
        "    \n",
        "\n",
        "    self.list_layers = list(self.backbone_net.children())[:-3]\n",
        "    #weight=self.list_layers[0].weight.clone()\n",
        "    self.list_layers[0]=nn.Conv2d(280,64,(3,3),stride=2,padding=1)\n",
        "\n",
        "    #self.backbone_net = nn.ModuleList(self.list_layers)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, X):\n",
        "    outputs = []\n",
        "    print(self.list_layers[0])\n",
        "    for i,layer in enumerate(self.list_layers):\n",
        "      X = layer(X)\n",
        "      outputs.append(X)\n",
        "\n",
        "    return outputs[-1]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxUzD_ZoAMSs"
      },
      "outputs": [],
      "source": [
        "class sub_block(nn.Module):\n",
        "  def __init__(self,ch):\n",
        "    super(sub_block, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(ch,ch//4,3, stride = 1, padding=1)\n",
        "    self.conv2 = nn.Conv2d(ch//4,ch//2,(3,3), stride = 1, padding=1)\n",
        "    self.usample=nn.Upsample(scale_factor = 2)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X=self.conv1(X)\n",
        "    X=self.conv2(X)\n",
        "    #print(X.size())\n",
        "    X=self.usample(X)\n",
        "    return X\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, ):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.block1=sub_block(256)\n",
        "    self.block2=sub_block(128)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.conv=nn.Conv2d(32,8,(3,3),padding=1,stride=1)\n",
        "    self.usample1=nn.Upsample(scale_factor = 2)\n",
        "    self.convpoint=nn.Conv2d(8,6,1)\n",
        "    self.block3=sub_block(64)\n",
        "    self.block4=sub_block(32)\n",
        "  def forward(self, X):\n",
        "    X=self.block1(X)\n",
        "    X=self.block2(X)\n",
        "    X=self.block3(X)\n",
        "    #X=self.block4(X)\n",
        "    X=self.conv(X)\n",
        "    X=self.relu(X)\n",
        "    X=self.usample1(X)\n",
        "    #print(X.size())\n",
        "    X=self.convpoint(X)\n",
        "    X=self.relu(X)\n",
        "    return X\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBq4uUGzahdB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcIzGLIFpPPu"
      },
      "outputs": [],
      "source": [
        "def getheatmap(img,xc,yc,height,width):\n",
        "  img=((np.exp(-(((np.arange(224)-xc)/(width/10))**2)/2)).reshape(1,-1)*(np.exp(-(((np.arange(224)-yc)/(height/10))**2)/2)).reshape(-1,1))\n",
        "  return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_6CBkjqbDEnS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80863cd5-a60d-4880-ce7f-0759873abe3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NteY_4BX_SCw"
      },
      "outputs": [],
      "source": [
        "def preprocesslabel():\n",
        "  path='/content/drive/MyDrive/data/thoracic/Preprocessing/CroppingCode/BoundingBox/spinalBoundfile.txt'\n",
        "  path2='/content/drive/MyDrive/data/thoracic/Preprocessing/CroppingCode/BoundingBox/ThoraxSpinalBoundBox/'\n",
        "  inpfie=open(path,'r')\n",
        "  path3=[]\n",
        "  lines=inpfie.readlines()\n",
        "  for line in lines:\n",
        "    line=line[3:21]\n",
        "    path3.append(path2+line)\n",
        "    #print(line)\n",
        "  inpfie.close()\n",
        "  path3=path3[24:]\n",
        "  inputimage=np.zeros((36,280,224,224))\n",
        "  i=0\n",
        "  for path in path3:\n",
        "    path=path+'/img_Bound.npy'\n",
        "    img=np.load(path)\n",
        "    img=np.array(img,dtype='float32')\n",
        "    imge=np.zeros((img.shape[0],224,224),dtype='float32')\n",
        "    j=0\n",
        "    for im in img:\n",
        "      im=cv2.resize(im,(224,224))\n",
        "      imge[j]=im\n",
        "      j=j+1\n",
        "    imge=np.array(imge,dtype=int)\n",
        "    inputimage[i][:imge.shape[0]]=imge\n",
        "    i=i+1\n",
        "  #input\n",
        "  return inputimage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOzkgiT4JGpG"
      },
      "outputs": [],
      "source": [
        "input=preprocesslabel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7MgW3fFqvlN"
      },
      "outputs": [],
      "source": [
        "input[15].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Umop5HRlMMCg"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EddEoSei0Wud"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model,self).__init__()\n",
        "    self.encoder=Encoder()\n",
        "    self.decoder=Decoder()\n",
        "  \n",
        "  def forward(self,inp):\n",
        "    inp=self.encoder(inp)\n",
        "    inp=self.decoder(inp)\n",
        "    return inp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir9ASKlT1kqv"
      },
      "outputs": [],
      "source": [
        "model=Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bX-VcdOX0iWQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV0qNwQmzlwD"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "los = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AOR9FVm311g"
      },
      "outputs": [],
      "source": [
        "path='/content/drive/MyDrive/data/thoracic/Preprocessing/CroppingCode/BoundingBox/spinalBoundfile.txt'\n",
        "inpfie=open(path,'r')\n",
        "lines=inpfie.readlines()\n",
        "lines\n",
        "out=[]\n",
        "for line in lines:\n",
        "  line=line[55:]\n",
        "  line=line.split(',',6)\n",
        "  line=line[:6]\n",
        "  if line[0][0]==' ':\n",
        "    line[0]=line[0][1:]\n",
        "  #print(line)\n",
        "  outp=np.zeros((6,224,224))\n",
        "  i=0\n",
        "  for lin in line:\n",
        "    lin=(int)(lin)//(512//224)\n",
        "    li=np.zeros((224,224),float)\n",
        "    li=getheatmap(li,lin,lin,50,50)\n",
        "    outp[i]=np.array(li)\n",
        "    i=i+1\n",
        "  out.append(outp)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPQyuXFNhZXe"
      },
      "outputs": [],
      "source": [
        "out=np.array(out)\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OA00_-IuY_3"
      },
      "outputs": [],
      "source": [
        "input=np.array(input)\n",
        "input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1jnOyGepyMm"
      },
      "outputs": [],
      "source": [
        "o=out[24:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFT-a0WpuVR6"
      },
      "outputs": [],
      "source": [
        "o.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp_cbXeU2WHo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "x=input\n",
        "y=o\n",
        "\n",
        "tensor_x = torch.Tensor(x) \n",
        "tensor_y = torch.Tensor(y)\n",
        "\n",
        "my_dataset = TensorDataset(tensor_x,tensor_y) \n",
        "train_loader = DataLoader(my_dataset,batch_size=10) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOF0e_qzL_QJ"
      },
      "outputs": [],
      "source": [
        "def cee(out,lab):\n",
        "  sum=0.0\n",
        "  X = out\n",
        "  Y = lab\n",
        "  n = len(X)\n",
        "  for i in range(0,n): \n",
        "    oupt = model(X[i])\n",
        "    soft = torch.softmax(oupt, dim=0)\n",
        "    target = Y[i]\n",
        "    p = soft[target]  \n",
        "    sum += torch.log(p)\n",
        "  return -sum / n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma = 1.0):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = torch.tensor(gamma, dtype = torch.float32)\n",
        "        self.eps = 1e-6\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        probs = torch.sigmoid(input)\n",
        "        log_probs = -torch.log(probs)\n",
        "        focal_loss = torch.sum(  torch.pow(1-probs + self.eps, self.gamma).mul(log_probs).mul(target)  , dim=1)\n",
        "        return focal_loss.mean()"
      ],
      "metadata": {
        "id": "e93Uau3IuPO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foc=FocalLoss(1)"
      ],
      "metadata": {
        "id": "32MJpVoi08V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=nn.MSELoss()"
      ],
      "metadata": {
        "id": "RM10IziO0xtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLGWp4-YId6a"
      },
      "outputs": [],
      "source": [
        "for epoch in range(20):  \n",
        "    running_loss = 0.0\n",
        "    for i,data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = l(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        #if i % 2 == 1:  \n",
        "        print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss  :.3f}')\n",
        "        running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3HMHLWZIfjb"
      },
      "outputs": [],
      "source": [
        "out=model(inputs[0].reshape(1,280,224,224)).detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(out[0][5])"
      ],
      "metadata": {
        "id": "VvFR0SN210vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow()"
      ],
      "metadata": {
        "id": "wrYoUGB-eTv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(o[0][5])"
      ],
      "metadata": {
        "id": "pe6uXhwu0adI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "centernetmodel.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4zM9ppP7lK5BSsRpa/r0j",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}